{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infectious-excerpt",
   "metadata": {},
   "source": [
    "# Attacking an ML classifier for malicious IDS traffic\n",
    "\n",
    "In this part of the workshop we will generate adversarial samples to fool the classifiers from part 1\n",
    "\n",
    "There are many ways that an ML classifier can be manipulated. \n",
    "\n",
    "Model evasion attacks use adversarial samples, specially crafted samples which retain the original class in reality but are misclassified by the model\n",
    "\n",
    "There are many open source implemenations of adversarial attacks. Here we will use the [Adversarial Robustness Toolbox (ART)](https://github.com/Trusted-AI/adversarial-robustness-toolbox) which has the advantage of compatibility with multiple python machine learning libraries across many types of attack. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stylish-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import DecisionTreeAttack, HopSkipJump\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnDecisionTreeClassifier\n",
    "\n",
    "from models import Model\n",
    "from utils import compare_data, parse_df_for_pcap_validity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-preview",
   "metadata": {},
   "source": [
    "## White Box Attack\n",
    " \n",
    "First we will assume the adversary has full knowledge of the classifier and use the [Decision Tree Attack (Papernot, McDaniel, Goodfellow 2016)](https://arxiv.org/abs/1605.07277) (on the decision tree models). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "committed-volume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_model_path exists, loading model and config....\n",
      "DecisionTreeClassifier()\n",
      "['time_delta', 'IP__ttl', 'Ethernet__type_2048.0', 'Ethernet__type_2054.0', 'Ethernet__type_0.0', 'Ethernet__type_34525.0', 'Ethernet__type_32821.0', 'IP__proto_6.0', 'IP__proto_17.0', 'IP__proto_0.0', 'IP__proto_1.0', 'IP__proto_2.0']\n",
      "Classification before adversarial evasion\n",
      "Opening datasets/AdversaryPingFlood.pcap ...\n",
      "done parsing datasets/AdversaryPingFlood.pcap\n",
      "-----\n",
      "Testing acc: 0.94, f1: 0.97, tpr: 0.94, tnr 0.00\n",
      "[[   0    0]\n",
      " [ 114 1886]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Adversary has a pcap of 1 minute of Ping flood DDos that they have crafted \n",
    "# For the adversary: success = 0 packet detection but will settle for 90% getting through\n",
    "\n",
    "attack_data_pcap = \"datasets/AdversaryPingFlood.pcap\"\n",
    "\n",
    "# load up the stolen IDS classifier\n",
    "model = Model(None, save_model_name=\"time_model_dt\")\n",
    "\n",
    "# check how well the model works at detecting the packets so far\n",
    "print(\"Classification before adversarial evasion\")\n",
    "target_attack_x, target_attack_y, preds = model.test(attack_data_pcap, malicious=1, return_x_y_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daily-tennessee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1306f8956c14386a70177d0ce92cd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decision tree attack:   0%|          | 0/1886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get packets classified as malicious - these are the ones we want to manipulate\n",
    "target_attack_x, target_attack_y = target_attack_x[np.where(preds == 1)], target_attack_y[np.where(preds == 1)]\n",
    "\n",
    "# add ART wrapper to classifier\n",
    "art_classifier = ScikitlearnDecisionTreeClassifier(model=model.get_classifier())\n",
    "\n",
    "# create DecisionTreeAttack instance and pass ART classifier \n",
    "dt_attack = DecisionTreeAttack(classifier=art_classifier)\n",
    "\n",
    "# generate adversarial samples\n",
    "x_test_adv = dt_attack.generate(x=target_attack_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rapid-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification after adversarial evasion\n",
      "-----\n",
      "Testing acc: 0.00, f1: 0.00, tpr: 0.00, tnr 0.00\n",
      "[[   0    0]\n",
      " [1885    1]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Check new classification accuracy\n",
    "print(\"Classification after adversarial evasion\")\n",
    "model.test((x_test_adv, np.ones(len(x_test_adv))), malicious=target_attack_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "synthetic-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0\n",
      "   IP__ttl\n",
      "0   64.000\n",
      "1   32.499\n",
      "sample 1\n",
      "   time_delta  IP__ttl\n",
      "0    0.000515   64.000\n",
      "1   -0.000958   32.499\n",
      "sample 2\n",
      "   time_delta  IP__proto_1.0\n",
      "0    0.049520          1.000\n",
      "1    0.004405          0.499\n"
     ]
    }
   ],
   "source": [
    "# Checking for packet validity: compare the differences between the packets\n",
    "for i, (before, after) in enumerate(zip(target_attack_x, x_test_adv)):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print(\"sample\", i)\n",
    "    compare_data(before, after, model.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "physical-seating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0\n",
      "   IP__ttl\n",
      "0     64.0\n",
      "1     32.0\n",
      "sample 1\n",
      "   time_delta  IP__ttl\n",
      "0    0.000515     64.0\n",
      "1    0.000000     32.0\n",
      "sample 2\n",
      "   time_delta  IP__proto_1.0\n",
      "0    0.049520          1.000\n",
      "1    0.004405          0.499\n",
      "Classification after adversarial evasion + packet validation\n",
      "-----\n",
      "Testing acc: 0.00, f1: 0.00, tpr: 0.00, tnr 0.00\n",
      "[[   0    0]\n",
      " [1885    1]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "### fix the \"illegal\" changes:\n",
    "x_test_adv = parse_df_for_pcap_validity(x_test_adv, original_data=target_attack_x, columns=model.features)\n",
    "\n",
    "# compare against original\n",
    "for i, (before, after) in enumerate(zip(target_attack_x, x_test_adv)):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print(\"\\n sample\", i)\n",
    "    compare_data(before, after, model.features)\n",
    "\n",
    "# test new classification accuracy on \"fixed\" adversarial samples\n",
    "print(\"Classification after adversarial evasion + packet validation\")\n",
    "model.test((x_test_adv, np.ones(len(x_test_adv))), malicious=target_attack_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-colon",
   "metadata": {},
   "source": [
    "## Black(ish) Box Attack\n",
    "\n",
    "Now we assume the attacker can only see the label coming out of the IDS, does not know the algorithm being used, the features being used or how they are represented (we actually do know a little how they are represented - hence black-ish). \n",
    "\n",
    "Here we use the [HopSkipJump Attack (Chen, Jordan, Wainwright)](https://arxiv.org/abs/1904.02144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extended-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_model_path exists, loading model and config....\n",
      "DecisionTreeClassifier()\n",
      "['time_delta', 'IP__ttl', 'Ethernet__type_2048.0', 'Ethernet__type_2054.0', 'Ethernet__type_0.0', 'Ethernet__type_34525.0', 'Ethernet__type_32821.0', 'IP__proto_6.0', 'IP__proto_17.0', 'IP__proto_0.0', 'IP__proto_1.0', 'IP__proto_2.0']\n",
      "Original accuracy\n",
      "-----\n",
      "Testing acc: 0.00, f1: 0.00, tpr: 0.00, tnr 0.00\n",
      "[[   0    0]\n",
      " [1885    1]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "model = Model(None, save_model_name=\"time_model_dt\")\n",
    "\n",
    "# review test accuracy\n",
    "print(\"Original accuracy\")\n",
    "model.test(x_test_adv, malicious=target_attack_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "floppy-table",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a2353d60d146569329c149498fc29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HopSkipJump:   0%|          | 0/1886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification after black-box adversarial evasion\n",
      "-----\n",
      "Testing acc: 0.00, f1: 0.00, tpr: 0.00, tnr 0.00\n",
      "[[   0    0]\n",
      " [1886    0]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# create ART wrapper for model\n",
    "art_classifier = SklearnClassifier(model=model.get_classifier())\n",
    "\n",
    "# Initiate HopSkipJump and \n",
    "attack = HopSkipJump(classifier=art_classifier)\n",
    "x_test_adv = attack.generate(x=target_attack_x, y=np.zeros(len(target_attack_x)))\n",
    "\n",
    "# check new classification accuracy\n",
    "print(\"Classification after black-box adversarial evasion\")\n",
    "model.test((x_test_adv, np.ones(len(x_test_adv))), malicious=target_attack_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opened-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0\n",
      "   time_delta    IP__ttl  Ethernet__type_2048.0  Ethernet__type_2054.0  \\\n",
      "0    0.000000  64.000000               1.000000               0.000000   \n",
      "1    0.064538  64.026192               0.998389               0.005513   \n",
      "\n",
      "   Ethernet__type_0.0  Ethernet__type_34525.0  Ethernet__type_32821.0  \\\n",
      "0            0.000000                0.000000                0.000000   \n",
      "1            0.000506                0.008076                0.003619   \n",
      "\n",
      "   IP__proto_6.0  IP__proto_17.0  IP__proto_0.0  IP__proto_1.0  IP__proto_2.0  \n",
      "0       0.000000        0.000000       0.000000       1.000000       0.000000  \n",
      "1       0.002838        0.004043       0.000051       1.004305       0.005235  \n",
      "sample 1\n",
      "   time_delta    IP__ttl  Ethernet__type_2048.0  Ethernet__type_2054.0  \\\n",
      "0    0.000515  64.000000               1.000000               0.000000   \n",
      "1    0.030747  63.970646               1.005681               0.002443   \n",
      "\n",
      "   Ethernet__type_0.0  Ethernet__type_32821.0  IP__proto_6.0  IP__proto_17.0  \\\n",
      "0            0.000000                0.000000       0.000000        0.000000   \n",
      "1            0.000456                0.000712       0.000049        0.001427   \n",
      "\n",
      "   IP__proto_0.0  IP__proto_1.0  IP__proto_2.0  \n",
      "0       0.000000       1.000000       0.000000  \n",
      "1       0.002927       1.000565       0.002301  \n",
      "sample 2\n",
      "   time_delta    IP__ttl  Ethernet__type_2048.0  Ethernet__type_2054.0  \\\n",
      "0    0.049520  64.000000               1.000000                0.00000   \n",
      "1    0.926098  66.289398               1.133474                0.00134   \n",
      "\n",
      "   Ethernet__type_0.0  Ethernet__type_34525.0  Ethernet__type_32821.0  \\\n",
      "0            0.000000                0.000000                0.000000   \n",
      "1            0.071723                0.028731                0.186295   \n",
      "\n",
      "   IP__proto_6.0  IP__proto_17.0  IP__proto_0.0  IP__proto_1.0  IP__proto_2.0  \n",
      "0       0.000000        0.000000       0.000000       1.000000       0.000000  \n",
      "1       0.054824        0.196977       0.014185       1.253093       0.057518  \n"
     ]
    }
   ],
   "source": [
    "# compare against original\n",
    "for i, (before, after) in enumerate(zip(target_attack_x, x_test_adv)):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print(\"\\n sample\", i)\n",
    "    compare_data(before, after, model.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exciting-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification after adversarial evasion + packet validation\n",
      "-----\n",
      "Testing acc: 0.00, f1: 0.00, tpr: 0.00, tnr 0.00\n",
      "[[   0    0]\n",
      " [1886    0]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "### parse packets for illegal changes \n",
    "x_test_adv = parse_df_for_pcap_validity(x_test_adv, target_attack_x, columns=model.features)\n",
    "    \n",
    "# test new classification accuracy on \"fixed\" adversarial samples\n",
    "print(\"Classification after adversarial evasion + packet validation\")\n",
    "model.test((x_test_adv, np.ones(len(x_test_adv))), malicious=target_attack_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-peter",
   "metadata": {},
   "source": [
    "### Part 2 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "national-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different decision tree models for the white box attack above \n",
    "# i.e. replace model name in the first section with one of these: \n",
    "decision_tree_models = [\"time_model_dt\", \n",
    "                        \"all_except_src_dst_dt\", \n",
    "                        \"all_dt\", \n",
    "                        \"tcp_udp_modbus_icmp_boot_dt\", \n",
    "                        \"src_dst_features_dt\", \n",
    "                        \"IP_features_dt\"]\n",
    "# or use a model you trained in the previous section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lyric-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the black-box attack with different models (any algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lined-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the adversarial samples generated for one model also fool another (is there transferability)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "viral-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions\n",
    "# Does it always matter if the packets are valid?\n",
    "# Which features are most commonly manipulated?\n",
    "# Does changing the algorithm change which features are changed?\n",
    "# Did you predictions from the previous section hold here?\n",
    "# Which scenario do you think is more likely? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "according-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- end of part 1 ------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
